{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab_Plant_Patho_2021_InceptionResNetV2_ImageDataGen.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv8FMcePj_3h",
        "outputId": "d79b1dae-480e-4cad-e8af-42ef34a9a6d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXLIRBDwkQ67",
        "outputId": "7b095948-4d54-46bf-e6b8-b52445477862"
      },
      "source": [
        "cd Plant"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Plant\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mrb2VgQkY6V"
      },
      "source": [
        "!mkdir Plant\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQWWBn6_kfxn",
        "outputId": "f5951a49-4871-406b-8d5c-da3fb00ae1d7"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Palnt_Patho_2021.ipynb  \u001b[0m\u001b[01;34mPlant\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acZ--7TukqSl",
        "outputId": "4c6588f8-e775-4a5f-910d-40d7699e4a03"
      },
      "source": [
        "cd Plant"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Plant\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7CxaHDXkrfW"
      },
      "source": [
        "!mkdir train_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocAM2Rrdktvn",
        "outputId": "dcbe5a14-9529-4167-cb23-e791064fd4b9"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_submission.csv  train_comp.csv  train_images_comp.rar\n",
            "\u001b[0m\u001b[01;34mtest_images\u001b[0m/           \u001b[01;34mtrain_images\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uvJ6FeOlAsG"
      },
      "source": [
        "!unrar x train_images_comp.rar train_images "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcNr8gSijFK4",
        "outputId": "35b69f16-745c-4f9e-be94-7e967c9dcd49"
      },
      "source": [
        "ls -1 /content/drive/MyDrive/Colab\\ Notebooks/Plant/train_images/ | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Idg3QtzJtJ2O",
        "outputId": "a255b6d7-85af-4abf-ec17-90dbfd4d825f"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/Plant'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drzz-Ny2tLsa",
        "outputId": "66b218a9-be25-4e50-9a0a-da8b0f8a761a"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_submission.csv  train_comp.csv  train_images_comp.rar\n",
            "\u001b[0m\u001b[01;34mtest_images\u001b[0m/           \u001b[01;34mtrain_images\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbme9GvqtP0l",
        "outputId": "7c8f788e-99e7-4811-86a0-e46e672dfa68"
      },
      "source": [
        "ls -1 /content/drive/MyDrive/Colab\\ Notebooks/Plant/train_images/ | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkajKAnnToX_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tensorflow.keras import layers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras import Sequential\n",
        "from tensorflow.keras.applications import InceptionResNetV2, Xception, MobileNetV2\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "from time import time\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta-8U8DmT-7c",
        "outputId": "99ba2f34-8212-45a4-f2ec-ac37c5f75839"
      },
      "source": [
        "# load dataset\n",
        "\n",
        "# sur colab\n",
        "# TRAIN_IMAGES_PATH = \"F:/Projet_computer_vision/plant-pathology-2021-fgvc8/train_images/\"\n",
        "\n",
        "# # en local\n",
        "# TRAIN_IMAGES_PATH = \"F:/Projet_computer_vision/plant-pathology-2021-fgvc8/compressed/train_images/\"\n",
        "# TEST_IMAGES_PATH = \"F:/Projet_computer_vision/plant-pathology-2021-fgvc8/test_images/\"\n",
        "# sur colab\n",
        "TRAIN_IMAGES_PATH = \"drive/MyDrive/Colab Notebooks/Plant/train_images/\"\n",
        "TEST_IMAGES_PATH = \"drive/MyDrive/Colab Notebooks/Plant/test_images/\"\n",
        "\n",
        "# en local\n",
        "# TRAIN_PATH = \"F:/Projet_computer_vision/plant-pathology-2021-fgvc8/compressed/train_comp.csv\"\n",
        "# SUB_PATH = \"F:/Projet_computer_vision/plant-pathology-2021-fgvc8/sample_submission.csv\"\n",
        "\n",
        "# sur colab\n",
        "TRAIN_PATH = \"drive/MyDrive/Colab Notebooks/Plant/train_comp.csv\"\n",
        "SUB_PATH = \"drive/MyDrive/Colab Notebooks/Plant/sample_submission.csv\"\n",
        "\n",
        "train_data = pd.read_csv(TRAIN_PATH)\n",
        "print(\"train_data= \" , train_data[:5],\"\\n\")\n",
        "test_data = pd.read_csv(SUB_PATH)\n",
        "print(\"test_data= \", test_data,\"\\n\")\n",
        "# sub = pd.read_csv(SUB_PATH)\n",
        "\n",
        "# bon 3\n",
        "classes=set()\n",
        "for v in train_data[\"labels\"].values:\n",
        "    classes.update(set(v.split()))\n",
        "print(\"classes= \", classes,\"\\n\")\n",
        "\n",
        "#On peut associer les images des feuilles à 5 classes possibles:\n",
        "#'complex', 'frog_eye_leaf_spot', 'powdery_mildew', 'rust', 'scab'\n",
        "# healthy , quand aucune de ces classes n'est là.\n",
        "\n",
        "train_data['scab']=train_data['labels'].apply(lambda x: 1 if 'scab' in x else 0) \n",
        "train_data['rust']=train_data['labels'].apply(lambda x: 1 if 'rust' in x else 0) \n",
        "train_data['powdery_mildew']=train_data['labels'].apply(lambda x: 1 if 'powdery_mildew' in x else 0) \n",
        "train_data['frog_eye_leaf_spot']=train_data['labels'].apply(lambda x: 1 if 'frog_eye_leaf_spot' in x else 0) \n",
        "train_data['complex']=train_data['labels'].apply(lambda x: 1 if 'complex' in x else 0) \n",
        "# train_data\n",
        "print(\"train_data ave 5 colonnes de labels = \")\n",
        "print(train_data[:3],\"\\n\")\n",
        "\n",
        "labels_titles=[\"scab\",\"rust\",\"powdery_mildew\",\"frog_eye_leaf_spot\",\"complex\"]\n",
        "\n",
        "# sur colab\n",
        "def add_path_compressed_train(file):\n",
        "    return TRAIN_IMAGES_PATH  + file\n",
        "\n",
        "def add_path_test(file):\n",
        "    return TEST_IMAGES_PATH + file\n",
        "\n",
        "train_files= train_data.image.map(add_path_compressed_train).values\n",
        "print(\"train_files= \\n\", train_files[:3],\"\\n\")\n",
        "\n",
        "test_files= test_data.image.map(add_path_test).values\n",
        "print(\"test_files= \\n\", test_files,\"\\n\")\n",
        "\n",
        "labels = np.float32(train_data.loc[:, 'scab':'complex'].values)\n",
        "print(\"labels= \\n \", labels[:3],\"\\n\")\n",
        "\n",
        "print(\"shapes= \", train_files.shape, labels.shape,\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data=                               image                           labels\n",
            "0  Compressed_800113bb65efe69e.jpg                          healthy\n",
            "1  Compressed_8002cb321f8bfcdf.jpg  scab frog_eye_leaf_spot complex\n",
            "2  Compressed_80070f7fb5e2ccaa.jpg                             scab\n",
            "3  Compressed_80077517781fb94f.jpg                             scab\n",
            "4  Compressed_800cbf0ff87721f8.jpg                          complex \n",
            "\n",
            "test_data=                    image   labels\n",
            "0  85f8cb619c66b863.jpg  healthy\n",
            "1  ad8770db05586b59.jpg  healthy\n",
            "2  c7b03e718489f3ca.jpg  healthy \n",
            "\n",
            "classes=  {'rust', 'healthy', 'powdery_mildew', 'complex', 'frog_eye_leaf_spot', 'scab'} \n",
            "\n",
            "train_data ave 5 colonnes de labels = \n",
            "                             image  ... complex\n",
            "0  Compressed_800113bb65efe69e.jpg  ...       0\n",
            "1  Compressed_8002cb321f8bfcdf.jpg  ...       1\n",
            "2  Compressed_80070f7fb5e2ccaa.jpg  ...       0\n",
            "\n",
            "[3 rows x 7 columns] \n",
            "\n",
            "train_files= \n",
            " ['drive/MyDrive/Colab Notebooks/Plant/train_images/Compressed_800113bb65efe69e.jpg'\n",
            " 'drive/MyDrive/Colab Notebooks/Plant/train_images/Compressed_8002cb321f8bfcdf.jpg'\n",
            " 'drive/MyDrive/Colab Notebooks/Plant/train_images/Compressed_80070f7fb5e2ccaa.jpg'] \n",
            "\n",
            "test_files= \n",
            " ['drive/MyDrive/Colab Notebooks/Plant/test_images/85f8cb619c66b863.jpg'\n",
            " 'drive/MyDrive/Colab Notebooks/Plant/test_images/ad8770db05586b59.jpg'\n",
            " 'drive/MyDrive/Colab Notebooks/Plant/test_images/c7b03e718489f3ca.jpg'] \n",
            "\n",
            "labels= \n",
            "  [[0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 1.]\n",
            " [1. 0. 0. 0. 0.]] \n",
            "\n",
            "shapes=  (18632,) (18632, 5) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7_qileUD0zw"
      },
      "source": [
        "def imagedatagen():\n",
        "\n",
        "        train_datagen = ImageDataGenerator(\n",
        "        rescale=1 / 255.0,\n",
        "        rotation_range=20,\n",
        "        zoom_range=0.05,\n",
        "        width_shift_range=0.05,\n",
        "        height_shift_range=0.05,\n",
        "        shear_range=0.05,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\")\n",
        "        # validation_split=0.20)\n",
        "\n",
        "        valid_test_datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
        "        \n",
        "        test_datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
        "        \n",
        "        \n",
        "        \n",
        "        return(train_datagen, valid_test_datagen, test_datagen)\n",
        "    \n",
        "\n",
        "def make_train_valid_test_generators(train_datagen,valid_test_datagen, test_datagen, train_data, valid_data, test_data, batch_size):\n",
        "   \n",
        "    \n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_data,\n",
        "        directory=TRAIN_IMAGES_PATH,\n",
        "        x_col=\"image\",\n",
        "        y_col=labels_titles,\n",
        "        target_size=(100, 100),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"raw\",\n",
        " #       subset='training',\n",
        "        shuffle=True,\n",
        "        seed=42\n",
        "    )\n",
        "    valid_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=valid_data,\n",
        "        directory=TRAIN_IMAGES_PATH,\n",
        "        x_col=\"image\",\n",
        "        y_col=labels_titles,\n",
        "        target_size=(100, 100),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"raw\",\n",
        "#        subset='validation',\n",
        "        shuffle=True,\n",
        "        seed=42\n",
        "    )\n",
        "    \n",
        "        \n",
        "    valid_test_generator = valid_test_datagen.flow_from_dataframe(\n",
        "        dataframe=valid_data,\n",
        "        directory=TRAIN_IMAGES_PATH,\n",
        "        x_col=\"image\",        \n",
        "        target_size=(100, 100),\n",
        "        batch_size=1,\n",
        "        class_mode=None,\n",
        "        shuffle=False,\n",
        "    )   \n",
        "\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_data,\n",
        "        directory=TEST_IMAGES_PATH,\n",
        "        x_col=\"image\",\n",
        "        target_size=(100, 100),\n",
        "        batch_size=1,\n",
        "        class_mode=None,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    \n",
        "\n",
        "    return train_generator,valid_generator,valid_test_generator, test_generator\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "def get_model(image_shape):\n",
        "    # InRes3\n",
        "    #Adding the final layers to the above base models where the actual classification is done in the dense layers\n",
        "    InResNetV2= InceptionResNetV2(include_top=False, weights=\"imagenet\", \\\n",
        "        input_tensor=None, input_shape=image_shape, pooling='avg') \n",
        "    model_InResNet2 = Sequential()\n",
        "    model_InResNet2.add(InResNetV2)\n",
        "    model_InResNet2.add(Dense(5, activation=('sigmoid')))\n",
        "\n",
        "    model_InResNet2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    model_InResNet2.summary()\n",
        "    return model_InResNet2\n",
        "\n",
        "\n",
        "def build_lrfn(lr_start=0.00001, lr_max=0.00005, \n",
        "               lr_min=0.00001, lr_rampup_epochs=5, \n",
        "               lr_sustain_epochs=0, lr_exp_decay=.8):\n",
        "    # lr_max = lr_max * strategy.num_replicas_in_sync\n",
        "\n",
        "    def lrfn(epoch):\n",
        "        if epoch < lr_rampup_epochs:\n",
        "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
        "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
        "            lr = lr_max\n",
        "        else:\n",
        "            lr = (lr_max - lr_min) *\\\n",
        "                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n",
        "                                - lr_sustain_epochs) + lr_min\n",
        "        return lr\n",
        "    return lrfn   \n",
        "\n",
        "\n",
        "def train(model, train_generator, valid_generator,epochs,  batch_size, filenum):\n",
        "         \n",
        "    \n",
        "    # learning rate\n",
        "    \n",
        "    lrfn = build_lrfn()\n",
        "\n",
        "    STEPS_PER_EPOCH = train_generator.n // batch_size\n",
        "    VALIDATION_STEPS = valid_generator.n// batch_size\n",
        "    # STEPS_PER_EPOCH = 10\n",
        "    # VALIDATION_STEPS=4\n",
        "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
        "\n",
        "    # Early Stopping\n",
        "    early_stop= EarlyStopping(monitor='val_accuracy',patience=5, mode='max' )\n",
        "\n",
        "    # save the weights given the best val_loss\n",
        "    filepath='drive/MyDrive/Colab Notebooks/Plant/IncRestV2-best-gen-062021-'+str(filenum)+'.hdf5'\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "    callbacks_list = [lr_schedule,early_stop, checkpoint ]\n",
        "    # callbacks_list = [lr_schedule ]\n",
        "    #Network=model.fit(train_dataset, steps_per_epoch=STEPS_PER_EPOCH, verbose=1, \\\n",
        "    #                            validation_data=valid_dataset,callbacks=callbacks_list,epochs=epochs)\n",
        "\n",
        "    Network =model.fit(train_generator, validation_data = valid_generator, \n",
        "                             epochs =epochs,steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                       validation_steps = VALIDATION_STEPS,callbacks=callbacks_list)\n",
        "    \n",
        "#     Network =model_InResNet2.fit(train_generator, validation_data = valid_generator, \n",
        "#                               epochs =epochs,steps_per_epoch=STEPS_PER_EPOCH,\n",
        "#                         validation_steps = VALIDATION_STEPS)\n",
        "    \n",
        "    \n",
        "    return Network\n",
        "    \n",
        "    \n",
        "def validate(model, validData, valid_test_generator,n): \n",
        "   \n",
        "   \n",
        "    valid_true_labels=np.float32(validData.loc[:, 'scab':'complex'].values)\n",
        "    \n",
        "    model = load_model(\"drive/MyDrive/Colab Notebooks/Plant/IncRestV2-best-gen-062021-\"+str(n)+\".hdf5\")\n",
        "    valid_pred = model.predict(valid_test_generator)\n",
        "       \n",
        "    \n",
        "    # c'est exactement : accuracy_score(valid_true_labels, np.round(valid_pred)) (from sklearn.metrics import accuracy_score)\n",
        "    accuracy= np.mean(np.all(valid_true_labels == np.round(valid_pred), axis=1))\n",
        "    \n",
        "    return accuracy\n",
        "\n",
        "# une autre manière pour calculer la validation accuracy qui donne le même résultat.\n",
        "def validate1(model, valid_dataset,len_valid): \n",
        "   \n",
        "    valid_true_labels=np.float32(validData.loc[:, 'scab':'complex'].values)\n",
        "    valid_pred = model.predict(valid_test_generator)\n",
        "    \n",
        "    accuracy_score(valid_true_labels, np.round(valid_pred))\n",
        "    \n",
        "    return accuracy\n",
        "\n",
        "# fonction qui trace les 2 courbes loss et validation loss ainsi que l'accuracy et la validation accuracy\n",
        "def loss_accuracy_curves(Network) :\n",
        "    plt.subplot(121)\n",
        "    plt.plot(Network.history['loss'],label='Train')\n",
        "    plt.plot(Network.history['val_loss'],label='Validation')\n",
        "    plt.ylabel('Loss',fontsize=20)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Training', 'Validation'], loc='best')  # upper\n",
        "\n",
        "    plt.subplot(122)\n",
        "    plt.plot(Network.history['accuracy'],label='Train')\n",
        "    plt.plot(Network.history['val_accuracy'],label='Validation')\n",
        "    plt.ylabel('Accuracy',fontsize=20)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Training', 'Validation'], loc='best')  # upper\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsjBAbrPEXH5",
        "outputId": "c80f578e-4002-42d1-a574-f60e8d214d80"
      },
      "source": [
        "image_size=(100, 100)\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "batch_size =16 # 16\n",
        "\n",
        "X = train_data   # fichiers des images des feuilles (18 632)\n",
        "\n",
        "cv = RepeatedKFold(n_splits=3, n_repeats=1, random_state=1)\n",
        "\n",
        "debut= time()\n",
        "\n",
        "def evaluate_model_plant_patho(X):\n",
        "    \n",
        " n=1\n",
        " list_val_accuracy=[]\n",
        "\n",
        " for train_ix, test_ix in cv.split(X):\n",
        "\n",
        "    print(\"Split des données entre train set et validation set en utlisant la 3-fold cross validation \")\n",
        "\n",
        "    trainData = X.iloc[train_ix]\n",
        "    validData = X.iloc[test_ix]\n",
        "\n",
        "\n",
        "\n",
        "    print(trainData.shape)  # 12 421 ou 12 422\n",
        "    print(validData.shape) # 6 211 ou 6 210\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\nCréation des ImageDataGenerator pour le train, la validation à tester et pour le test set\")    \n",
        "    train_datagen, valid_test_datagen, test_datagen = imagedatagen() \n",
        "\n",
        "    print(\"\\nCréation des train, validation et test generators \")\n",
        "\n",
        "    train_generator,valid_generator,valid_test_generator, test_generator= make_train_valid_test_generators(train_datagen,\\\n",
        "                                     valid_test_datagen,test_datagen, trainData, validData, test_data, batch_size)\n",
        "\n",
        "   \n",
        "\n",
        "    print(\"\\nCréation du modèle à partir d'une Keras application (deep learning pre-trained models)\")\n",
        "    print(\"https://keras.io/api/applications/ \")\n",
        "\n",
        "    image_shape = image_size + (3,) \n",
        "    model= get_model(image_shape)\n",
        "\n",
        "    print(\"\\ntraining\")\n",
        "    # training du modèle et sauvegarde du meilleur modèle (max val_accuracy) rencontré lors des epochs (sauvegarde des poids)\n",
        "    # train(model, train_dataset, valid_dataset, epochs=5, len_train=len_train, batch_size=16, filenum=n)\n",
        "    Network= train(model, train_generator, valid_generator,epochs=15 ,  batch_size=batch_size, filenum=n)\n",
        "\n",
        "   \n",
        "    # break\n",
        "    # faire une prediction du validation set à partir du modèle et la comparer aux vrais labels\n",
        "    # ça équivaut à un accuracy_score de sklearn.\n",
        "    # attention : c'est pas équivalent au model.evaluate(valid_dataset) de keras, ça ne donne pas les mêmes résultats car \n",
        "    # il s'agit d'une classification Multi-Class et multi-label.\n",
        "\n",
        "    print(\"\\n validation :prend du temps, car il faut faire une prévision pour tout le validation set: 6 211 images, le tiers de tout le dataset\")\n",
        "    val_accuracy = validate(model, validData, valid_test_generator,n) \n",
        "    \n",
        "    \n",
        "    # courbes de loss / validation loss et courbe d'accuracy / validation accuracy\n",
        "    loss_accuracy_curves(Network) \n",
        "    \n",
        "    # Sauvegarde de la val_accuracy dans uen liste pour un calcul de moyenne et d'écart-type\n",
        "    print('>>>>>>>>>>>>>>>>>>>>>>>>>>> validation_accuracy %.3f' % val_accuracy)\n",
        "    list_val_accuracy.append(val_accuracy)\n",
        "    \n",
        "    print(\"\\n >>>>>>>>>>>>>>>>>>>>>>>FIN Training et Cross validation :  \",n)\n",
        "    print(\"\\n\\n\")\n",
        "   \n",
        "    break;   \n",
        " \n",
        " return list_val_accuracy\n",
        "\n",
        "list_val_accuracy= evaluate_model_plant_patho(X)\n",
        "duree_totale = time()- debut\n",
        "print(\"Durée des 3 trainings basés sur le 3-fold cross-validation  (en secondes) =\", duree_totale)\n",
        "print('\\nValidation Accuracy: Moyenne %.3f Ecart-type(%.3f)' % (mean(list_val_accuracy), std(list_val_accuracy)))   \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Split des données entre train set et validation set en utlisant la 3-fold cross validation \n",
            "(12421, 7)\n",
            "(6211, 7)\n",
            "\n",
            "Création des ImageDataGenerator pour le train, la validation à tester et pour le test set\n",
            "\n",
            "Création des train, validation et test generators \n",
            "Found 12421 validated image filenames.\n",
            "Found 6211 validated image filenames.\n",
            "Found 6211 validated image filenames.\n",
            "Found 3 validated image filenames.\n",
            "\n",
            "Création du modèle à partir d'une Keras application (deep learning pre-trained models)\n",
            "https://keras.io/api/applications/ \n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 2s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_resnet_v2 (Functio (None, 1536)              54336736  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 7685      \n",
            "=================================================================\n",
            "Total params: 54,344,421\n",
            "Trainable params: 54,283,877\n",
            "Non-trainable params: 60,544\n",
            "_________________________________________________________________\n",
            "\n",
            "training\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "776/776 [==============================] - 6791s 9s/step - loss: 0.4839 - accuracy: 0.3739 - val_loss: 2188.9624 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.54736, saving model to drive/MyDrive/Colab Notebooks/Plant/IncRestV2-best-gen-062021-1.hdf5\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 1.8000000000000004e-05.\n",
            "776/776 [==============================] - 4951s 6s/step - loss: 0.3446 - accuracy: 0.5756 - val_loss: 7070.7725 - val_accuracy: 0.6424\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.54736 to 0.64240, saving model to drive/MyDrive/Colab Notebooks/Plant/IncRestV2-best-gen-062021-1.hdf5\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 2.6000000000000002e-05.\n",
            "776/776 [==============================] - 4859s 6s/step - loss: 0.3055 - accuracy: 0.6148 - val_loss: 4323.7700 - val_accuracy: 0.6669\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.64240 to 0.66688, saving model to drive/MyDrive/Colab Notebooks/Plant/IncRestV2-best-gen-062021-1.hdf5\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 3.4000000000000007e-05.\n",
            "776/776 [==============================] - 4906s 6s/step - loss: 0.2814 - accuracy: 0.6424 - val_loss: 2328.1223 - val_accuracy: 0.6624\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.66688\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
            "776/776 [==============================] - 4876s 6s/step - loss: 0.2583 - accuracy: 0.6631 - val_loss: 651.5428 - val_accuracy: 0.6883\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.66688 to 0.68831, saving model to drive/MyDrive/Colab Notebooks/Plant/IncRestV2-best-gen-062021-1.hdf5\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 5e-05.\n",
            "776/776 [==============================] - 4898s 6s/step - loss: 0.2376 - accuracy: 0.6950 - val_loss: 345.1974 - val_accuracy: 0.7060\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.68831 to 0.70602, saving model to drive/MyDrive/Colab Notebooks/Plant/IncRestV2-best-gen-062021-1.hdf5\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
            "776/776 [==============================] - 4899s 6s/step - loss: 0.2173 - accuracy: 0.7085 - val_loss: 606.4861 - val_accuracy: 0.6960\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.70602\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 3.5600000000000005e-05.\n",
            "776/776 [==============================] - 4917s 6s/step - loss: 0.2007 - accuracy: 0.7240 - val_loss: 286.9608 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.70602\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 3.0480000000000006e-05.\n",
            "365/776 [=============>................] - ETA: 35:25 - loss: 0.1786 - accuracy: 0.7434"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONK7TKO219oI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}